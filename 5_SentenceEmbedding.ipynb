{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"5_SentenceEmbedding.ipynb","provenance":[],"collapsed_sections":["6-720HWYZQc-","dolmokizNtbM","PLHWWC83_edW","Hqm1WeuqlRQM","Gyp7KhjtJcC_","kuu4uqlILe1V","jDJHFWAsWOlX"],"machine_shape":"hm"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-qZBlH1bDqwO","colab_type":"text"},"source":["<center><h1>Stack Overflow Search Engine</h1></center>"]},{"cell_type":"code","metadata":{"id":"-fn7T4kaY85X","colab_type":"code","colab":{}},"source":["#installing packages (since i'm using google colab,i'm installing from notebook itself)\n","\n","#%%capture\n","##Install the latest Tensorflow version.\n","#!pip3 install --upgrade tensorflow-gpu\n","##Install TF-Hub.\n","#!pip3 install tensorflow-hub\n","#!pip install bert-tensorflow\n","#!pip install bert_embedding\n","#!pip3 install --upgrade gensim\n","#!pip3 install --upgrade numpy\n","#!pip install normalise\n","#import nltk\n","#nltk.download('punkt')\n","#nltk.download('brown')\n","#nltk.download('names')\n","#nltk.download('stopwords')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3vwuwsSiY-EY","colab_type":"code","colab":{}},"source":["#importing packages\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import seaborn as sns\n","import tensorflow_hub as tf_hub\n","import matplotlib.pyplot as plt\n","import multiprocessing as mp\n","import pickle\n","import time\n","import datetime\n","import os\n","import gensim\n","from gensim.models import LdaModel\n","from gensim import models, corpora, similarities\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.decomposition import TruncatedSVD\n","from scipy.stats import entropy\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import MinMaxScaler\n","from IPython.display import HTML\n","from scipy import sparse\n","\n","from functools import partial\n","import time\n","from datetime import datetime\n","\n","from google.colab import auth\n","from google.cloud import bigquery\n","from google.colab import drive"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tSY-_z5CZuV1","colab_type":"text"},"source":["<h1>Mounting the Drive </h1>"]},{"cell_type":"code","metadata":{"id":"H-T3TOtlZvGJ","colab_type":"code","outputId":"02a87083-da12-4ed2-ff55-a274d2caa70a","executionInfo":{"status":"ok","timestamp":1583925182073,"user_tz":-330,"elapsed":2335,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["drive.mount('/content/drive/', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DA_AJCIrZwzP","colab_type":"text"},"source":["<h1>Variables</h1>"]},{"cell_type":"code","metadata":{"id":"mNT4RLdtZwq5","colab_type":"code","colab":{}},"source":["currentDirectory = \"/content/drive/My Drive/pcase_study_1/\"\n","os.chdir(currentDirectory)\n","currentDirectory = \"\"\n","dataDirectory = currentDirectory + \"data/\"\n","modelsDirectory = currentDirectory + \"models/\"\n","column = 'complete_question'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TkBpGq8jVoyW","colab_type":"text"},"source":["<h1>Reading Word2Vec Model</h1>\n"]},{"cell_type":"code","metadata":{"id":"9c6ixPxNVoEX","colab_type":"code","colab":{}},"source":["#reading Pre-Trained W2V\n","model_w2v = gensim.models.word2vec.Word2Vec.load(modelsDirectory+'w2v.bin') #reading pre-trained"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d3SYejvIM5ke","colab_type":"text"},"source":["<h1>Loading Data</h1>"]},{"cell_type":"code","metadata":{"id":"HI06TjTXM5J9","colab_type":"code","colab":{}},"source":["#X_train = pd.read_csv(dataDirectory + 'train_data.csv')\n","#X_test = pd.read_csv(dataDirectory + 'test_data.csv')\n","#\n","#data =  pd.read_csv(dataDirectory + 'data.csv')\n","#data = data[['id','title']]\n","#\n","#searchData = pd.concat([X_train,X_test])\n","#searchData = searchData[['id',column,'score','tags','sentiment_polarity','sentiment_subjectivity','neg','neu','pos','compound']]\n","#\n","#data = pd.merge(searchData, data, how ='inner', on ='id')\n","#\n","#data.to_csv(dataDirectory + 'search_data.csv',encoding='utf-8',index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ys6uhGa3OgPF","colab_type":"code","outputId":"acd5816d-27fa-4aa0-888e-5bc52ff36022","executionInfo":{"status":"ok","timestamp":1583925464189,"user_tz":-330,"elapsed":63265,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":264}},"source":["data =  pd.read_csv(dataDirectory + 'search_data.csv')\n","scaler = MinMaxScaler()\n","data[['score']] = scaler.fit_transform(data[['score']])\n","data.head(2)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>complete_question</th>\n","      <th>score</th>\n","      <th>tags</th>\n","      <th>sentiment_polarity</th>\n","      <th>sentiment_subjectivity</th>\n","      <th>neg</th>\n","      <th>neu</th>\n","      <th>pos</th>\n","      <th>compound</th>\n","      <th>title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17343032</td>\n","      <td>implement converters entities java generics wo...</td>\n","      <td>0.000298</td>\n","      <td>java|spring|jsf|generics</td>\n","      <td>0.008679</td>\n","      <td>0.359622</td>\n","      <td>0.032</td>\n","      <td>0.798</td>\n","      <td>0.170</td>\n","      <td>0.9928</td>\n","      <td>Implement converters for entities with Java Ge...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>17110104</td>\n","      <td>method use instead hazelcastgetmapmap using pr...</td>\n","      <td>0.000060</td>\n","      <td>java|collections</td>\n","      <td>0.225000</td>\n","      <td>0.450000</td>\n","      <td>0.000</td>\n","      <td>0.943</td>\n","      <td>0.057</td>\n","      <td>0.2500</td>\n","      <td>What method should we use instead of Hazelcast...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id  ...                                              title\n","0  17343032  ...  Implement converters for entities with Java Ge...\n","1  17110104  ...  What method should we use instead of Hazelcast...\n","\n","[2 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"D2aTYnIbX-j5","colab_type":"text"},"source":["<p>Sentence Embedding is most important. It involves converting the text representation of the questions into a numerical vector space.</p>\n","\n","<p>Five different types of embedding techniques studied in this notebook.</p>\n","<ul>\n","<li>Average Word2Vec</li>\n","<li>TF-IDF Weighted Word2Vec</li>\n","<li>Smooth Inverse Frequency and Word2Vec</li>\n","<li>Universal Sentence Encode</li>\n","<li>BERT Embedding</li>\n","</ul>\n","\n","**<p>And we will be studying Document Similarity LDA (Latent Dirichlet Allocation) </p>**"]},{"cell_type":"markdown","metadata":{"id":"6-720HWYZQc-","colab_type":"text"},"source":["#<h1>1. Sentence Embedding using Average Word2Vec<h1>"]},{"cell_type":"code","metadata":{"id":"FFDBb7GsyDIY","colab_type":"code","colab":{}},"source":["def AvgWord2VecEmbeddings(sentences,model):\n","    vlookup = model.wv.vocab\n","    vectors = model.wv\n","    output = np.zeros(shape=(len(sentences), model.vector_size), dtype = np.float32)\n","\n","    for i,s in enumerate(sentences):\n","        idx = [vlookup[w].index for w in s.split() if w in vlookup]\n","        if len(idx) > 0:\n","            v  = np.sum(vectors.vectors[idx], axis=0)\n","            v *= 1/len(idx)\n","            output[i] = v           \n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8h58FtwnL826","colab_type":"code","outputId":"76ea56be-eea1-4b1a-ec1a-7c47dc8bb6da","executionInfo":{"status":"ok","timestamp":1583925556987,"user_tz":-330,"elapsed":152905,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["start_time = time.time()\n","questions = data[column].values\n","avg_W2V_emb = AvgWord2VecEmbeddings(questions, model_w2v)\n","print(\"time taken to convert {0} questions to vector using AvgW2V Model is {1} seconds\".format(len(questions),time.time() - start_time))\n","print(\"Shape of the Senetence embedding\",avg_W2V_emb.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time taken to convert 929480 questions to vector using AvgW2V Model is 92.81342315673828 seconds\n","Shape of the Senetence embedding (929480, 300)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dolmokizNtbM","colab_type":"text"},"source":["#<h1>2. Sentence Embedding using TF-IDF and Word2Vec<h1>"]},{"cell_type":"code","metadata":{"id":"Ak0whTL2NrTx","colab_type":"code","colab":{}},"source":["def TF_IDF_Word2VecEmbeddings(sentences,model_w2v,model_tfidf):\n","    vlookup = model_w2v.wv.vocab\n","    vectors = model_w2v.wv\n","    vocab_idf = dict(zip(model_tfidf.get_feature_names(), model_tfidf.idf_))\n","\n","    output = np.zeros(shape=(len(sentences), model_w2v.vector_size), dtype = np.float32)\n","\n","\n","    for i,s in enumerate(sentences):\n","        idx = [vlookup[w].index for w in s.split() if w in vlookup and w in vocab_idf ]\n","        idf = np.array([vocab_idf[w] for w in s.split() if w in vlookup and w in vocab_idf ])\n","\n","        if len(idx) > 0:\n","            v  = np.sum(vectors.vectors[idx] * idf[:,None] , axis=0)\n","            v *= 1/len(idx)\n","            output[i] = v           \n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AVd3EftENrxw","colab_type":"code","outputId":"c9cf28f0-e4de-42eb-e4d3-54f4b894a10d","executionInfo":{"status":"ok","timestamp":1583925902483,"user_tz":-330,"elapsed":496588,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["start_time = time.time()\n","#questions = data[column].values\n","model_tfidf = TfidfVectorizer(min_df=10)\n","model_tfidf.fit(questions)\n","print(\"time taken to build TF-IDF model is {0} seconds\".format(time.time() - start_time))\n","\n","start_time = time.time()\n","TF_IDF_W2V_emb = TF_IDF_Word2VecEmbeddings(questions,model_w2v,model_tfidf)\n","\n","print(\"time taken to convert {0} questions to vector using TF-IDF+W2V Model is {1} seconds\".format(len(questions),time.time() - start_time))\n","print(\"Shape of the Senetence embedding\",TF_IDF_W2V_emb.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time taken to build TF-IDF model is 121.35671138763428 seconds\n","time taken to convert 929480 questions to vector using TF-IDF+W2V Model is 224.0520215034485 seconds\n","Shape of the Senetence embedding (929480, 300)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PLHWWC83_edW","colab_type":"text"},"source":["#<h1>3. Sentence Embedding using Smooth Inverse Frequency and Word2Vec<h1>"]},{"cell_type":"markdown","metadata":{"id":"Yf3TI9VmaKcH","colab_type":"text"},"source":["<h2>Smooth Inverse Frequency</h2>\n","<p>Taking the average of the word embeddings in a sentence tends to give too much weight to words that are quite irrelevant, semantically speaking. Smooth Inverse Frequency tries to solve this problem in two ways:</p>\n","\n","<ul>\n","<li>\n","Weighting: SIF takes the weighted average of the word embeddings in the sentence. Every word embedding is weighted by a/(a + p(w)), where a is a parameter that is typically set to 0.001 and p(w) is the estimated frequency of the word in a reference corpus.\n","</li>\n","<li>\n","Common component removal: SIF computes the principal component of the resulting embeddings for a set of sentences. It then subtracts from these sentence embeddings their projections on their first principal component. This should remove variation related to frequency and syntax that is less relevant semantically.\n","</li>\n","</ul>\n","\n"]},{"cell_type":"code","metadata":{"id":"OMOA2VOJ_oxh","colab_type":"code","colab":{}},"source":["#https://github.com/PrincetonML/SIF/blob/master/src/SIF_embedding.py\n","def compute_pc(X,npc=1):\n","    \"\"\"\n","    Compute the principal components. DO NOT MAKE THE DATA ZERO MEAN!\n","    :param X: X[i,:] is a data point\n","    :param npc: number of principal components to remove\n","    :return: component_[i,:] is the i-th pc\n","    \"\"\"\n","    svd = TruncatedSVD(n_components=npc, n_iter=7, random_state=0)\n","    svd.fit(X)\n","    return svd.components_*0.5\n","\n","def remove_pc(X, npc=1):\n","    \"\"\"\n","    Remove the projection on the principal components\n","    :param X: X[i,:] is a data point\n","    :param npc: number of principal components to remove\n","    :return: XX[i, :] is the data point after removing its projection\n","    \"\"\"\n","    pc = compute_pc(X, npc)\n","    if npc==1:\n","        XX = X - X.dot(pc.transpose()) * pc\n","    else:\n","        XX = X - X.dot(pc.transpose()).dot(pc)\n","    return XX\n","\n","def SIFWord2VecEmbeddings(sentences,model, alpha=1e-3):\n","    vlookup = model.wv.vocab\n","    vectors = model.wv\n","    output = np.zeros(shape=(len(sentences), model.vector_size), dtype = np.float32)\n","\n","    Z = 0\n","    for k in vlookup:\n","        Z += vlookup[k].count # Compute the normalization constant Z\n","\n","    for i,s in enumerate(sentences):\n","        idx = [vlookup[w].index for w in s.split() if w in vlookup]\n","        sif = np.array([( alpha / (alpha + (vlookup[w].count / Z))) for w in s.split() if w in vlookup])\n","\n","        if len(idx) > 0:\n","            v  = np.sum(vectors.vectors[idx] * sif[:,None] , axis=0)\n","            v *= 1/len(idx)\n","            output[i] = v\n","    \n","    output = remove_pc(output, 2)\n","\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IxQEcbQwhH2f","colab_type":"code","outputId":"17cddd08-9c13-4385-c24f-7e89398e96eb","executionInfo":{"status":"ok","timestamp":1583926121755,"user_tz":-330,"elapsed":713112,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["start_time = time.time()\n","#questions = data[column].values\n","SIF_W2V_emb = SIFWord2VecEmbeddings(questions, model_w2v)\n","print(\"time taken to convert {0} questions to vector using SIF+W2V Model is {1} seconds\".format(len(questions),time.time() - start_time))\n","print(\"Shape of the Senetence embedding\",SIF_W2V_emb.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time taken to convert 929480 questions to vector using SIF+W2V Model is 219.27632856369019 seconds\n","Shape of the Senetence embedding (929480, 300)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hqm1WeuqlRQM","colab_type":"text"},"source":["#<h1>4.Universal Sentence Encoder</h1>"]},{"cell_type":"markdown","metadata":{"id":"py-gF1p4ftqj","colab_type":"text"},"source":["<p>The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.</p>\n","\n","<p>The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is variable length English text and the output is a 512 dimensional vector. We apply this model to the STS benchmark for semantic similarity, and the results can be seen in the example notebook made available. The universal-sentence-encoder model is trained with a deep averaging network encoder.</p>"]},{"cell_type":"code","metadata":{"id":"5PKB-D1jvWCq","colab_type":"code","colab":{}},"source":["module_USE_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n","model_USE = tf_hub.load(module_USE_url)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6iiKNrjgmpD_","colab_type":"code","colab":{}},"source":["def USE_Embeddings(sentences,model):\n","    output = np.zeros(shape=(len(sentences), 512), dtype = np.float32)\n","    for i,s in enumerate(sentences):\n","      v = np.array(model([s]))\n","      output[i] = v.reshape(-1) \n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHXuTrxmsLnT","colab_type":"code","outputId":"89145d04-b510-4744-e60a-fc9726292bee","executionInfo":{"status":"ok","timestamp":1582630591678,"user_tz":0,"elapsed":3274007,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["start_time = time.time()\n","questions = data[column].values\n","USE_emb = USE_Embeddings(questions, model_USE)\n","print(\"time taken to convert {0} questions to vector using Universal Sentence Encoder Model is {1} seconds\".format(len(questions),\n","                                                                                                                   time.time() - start_time))\n","print(\"Shape of the Senetence embedding\",USE_emb.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time taken to convert 929480 questions to vector using Universal Sentence Encoder Model is 5723.34011721611 seconds\n","Shape of the Senetence embedding (929480, 512)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-UCUMprh9hiJ","colab_type":"code","colab":{}},"source":["#np.save(modelsDirectory+'USE_emb', USE_emb)\n","USE_emb = np.load(modelsDirectory+'USE_emb.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gyp7KhjtJcC_","colab_type":"text"},"source":["#<h1>5. Sentence Encoder using BERT</h1>"]},{"cell_type":"markdown","metadata":{"id":"HutULfnWgBb1","colab_type":"text"},"source":["<h3>BERT: Bidirectional Encoder Representations from Transformers</h3>\n","\n","<p>BERT model published by the google is currently the state of the art model for doing NLP related tasks. BERT which is an LSTM model works based on the concept of attention trying to predict the next token based on the series of the previous tokens it encountered.BERT based embedding may prove useful for this project to extract more meaningful information from the post text</p>\n"]},{"cell_type":"code","metadata":{"id":"4gjJik1GRB7d","colab_type":"code","outputId":"4b0dc417-ab2d-479e-acdd-58835baac674","executionInfo":{"status":"ok","timestamp":1583926233789,"user_tz":-330,"elapsed":93900,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["from bert_embedding import BertEmbedding\n","model_bert = BertEmbedding()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Vocab file is not found. Downloading.\n","Downloading /root/.mxnet/models/book_corpus_wiki_en_uncased-a6607397.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/book_corpus_wiki_en_uncased-a6607397.zip...\n","Downloading /root/.mxnet/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EwcyZjrfRL5W","colab_type":"code","colab":{}},"source":["def BERT_Embeddings(sentences,model):\n","    output = np.zeros(shape=(len(sentences), 768), dtype = np.float32)\n","    for i,s in enumerate(sentences):\n","      v = model([s])[0][1]\n","      length = len(v)\n","      v = np.sum(v,axis=0)\n","      v *= 1/length\n","      output[i] = v\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhRFNd2qRWwa","colab_type":"code","colab":{}},"source":["start_time = time.time()\n","questions = data[column].values\n","BERT_emb = BERT_Embeddings(questions, model_bert)\n","print(\"time taken to convert {0} questions to vector using BERT Model is {1:0.2f} minutes\".format(len(questions),(time.time() - start_time)/60))\n","print(\"Shape of the Senetence embedding\",BERT_emb.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ek9VovBoZ8j1","colab_type":"code","colab":{}},"source":["#np.save(modelsDirectory+'BERT_emb', BERT_emb)\n","BERT_emb = np.load(modelsDirectory+'BERT_emb.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kuu4uqlILe1V","colab_type":"text"},"source":["#<h1>6. Similary Using Latent Dirichlet Allocation and Jensen-Shannon distance</h1>"]},{"cell_type":"markdown","metadata":{"id":"lBfzTxOchPQv","colab_type":"text"},"source":["<h3>LDA</h3>\n","\n","<p>Latent Dirichlet Allocation, is an unsupervised generative model that assigns topic distributions to documents.</p>\n","\n","</p>At a high level, the model assumes that each document will contain several topics, so that there is topic overlap within a document. The words in each document contribute to these topics. The topics may not be known a priori, and needn't even be specified, but the number of topics must be specified a priori. Finally, there can be words overlap between topics, so several topics may share the same words.</p>\n","\n","<p>The model generates to latent (hidden) variables \n","<ul>\n","<li>\n"," A distribution over topics for each document\n","</li>\n","<li>\n","A distribution over words for each topics\n","</li>\n","</ul>\n","</p>\n","\n","<p>After training, each document will have a discrete distribution over all topics, and each topic will have a discrete distribution over all words.</p>"]},{"cell_type":"code","metadata":{"id":"v4B96bu2Ldhl","colab_type":"code","colab":{}},"source":["def train_lda(data):\n","    \"\"\"\n","    This function trains the lda model\n","    We setup parameters like number of topics, the chunksize to use in Hoffman method\n","    We also do 2 passes of the data since this is a small dataset, so we want the distributions to stabilize\n","    \"\"\"\n","    num_topics = 750\n","    chunksize = 300\n","    dictionary = corpora.Dictionary(data)\n","    corpus = [dictionary.doc2bow(doc) for doc in data]\n","    t1 = time.time()\n","    # low alpha means each document is only represented by a small number of topics, and vice versa\n","    # low eta means each topic is only represented by a small number of words, and vice versa\n","    lda = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary,\n","                   alpha=1e-2, eta=0.5e-2, chunksize=chunksize, minimum_probability=0.0, passes=1)\n","    t2 = time.time()\n","    print(\"Time to train LDA model on \", len(data), \"questions: \", (t2-t1)/60, \"min\")\n","    return dictionary,corpus,lda"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6SGSYf2wQlJH","colab_type":"code","colab":{}},"source":["def mp_part(part):\n","    return part.apply(lambda x: [w for w in nltk.word_tokenize(x) if w in model_w2v.wv.vocab])\n","\n","cores = mp.cpu_count()*3\n","data_split = np.array_split(data[column], cores)\n","pool = mp.Pool(cores)\n","lda_data = pd.concat(pool.map(mp_part, data_split))\n","pool.close()\n","pool.join()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SDylL1cxBye5","colab_type":"code","colab":{}},"source":["dictionary_lda,corpus_lda,model_lda = train_lda(lda_data)\n","\n","with open(modelsDirectory+'model_lda.pickle', 'wb') as handle:\n","    pickle.dump(model_lda, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","with open(modelsDirectory+'dictionary_lda.pickle', 'wb') as handle:\n","    pickle.dump(dictionary_lda, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","with open(modelsDirectory+'corpus_lda.pickle', 'wb') as handle:\n","    pickle.dump(corpus_lda, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jXWpHqXuBya4","colab_type":"code","colab":{}},"source":["with open(modelsDirectory+'model_lda.pickle', 'rb') as handle:\n","    model_lda = pickle.load(handle)\n","with open(modelsDirectory+'corpus_lda.pickle', 'rb') as handle:\n","    corpus_lda = pickle.load(handle)\n","with open(modelsDirectory+'dictionary_lda.pickle', 'rb') as handle:\n","    dictionary_lda = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gv4GWt1pByWu","colab_type":"code","outputId":"e39f77bb-160f-45a0-d558-f933fa57b2ac","executionInfo":{"status":"ok","timestamp":1582976177666,"user_tz":-330,"elapsed":26355,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["random_article_index = np.random.randint(len(data))\n","bow = dictionary_lda.doc2bow([w for w in nltk.word_tokenize(data.iloc[random_article_index,1]) if w in model_w2v.wv.vocab])\n","\n","doc_distribution = np.array([tup[1] for tup in model_lda.get_document_topics(bow=bow)])\n","\n","# bar plot of topic distribution for this document\n","fig, ax = plt.subplots(figsize=(12,6));\n","# the histogram of the data\n","patches = ax.bar(np.arange(len(doc_distribution)), doc_distribution)\n","ax.set_xlabel('Topic ID', fontsize=15)\n","ax.set_ylabel('Topic Contribution', fontsize=15)\n","ax.set_title(\"Topic Distribution for Question \" + str(random_article_index), fontsize=20)\n","fig.tight_layout()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA1gAAAGoCAYAAABbkkSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEyxJkiRJ6sj/B+aTJaSKR/HZAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"L-qAcGLaLAUT","colab_type":"code","outputId":"e2831e9e-9175-4c90-ec45-9db1bd5e52b7","executionInfo":{"status":"ok","timestamp":1582981735162,"user_tz":-330,"elapsed":2687115,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["start_time = time.time()\n","\n","from tqdm import tqdm\n","\n","def LDA_topics(corpus,model):\n","    output = np.zeros(shape=(len(corpus), 750), dtype = np.float32)\n","    for i,s in enumerate(tqdm(corpus)):\n","      v =  np.array([[tup[1] for tup in lst] for lst in model[[s]]])\n","      output[i] = v\n","    return output\n","\n","doc_topic_dist = LDA_topics(corpus_lda,model_lda)\n","print(\"time taken to conevrt to topics {0} minutes\".format((time.time() - start_time)/60))\n","print(\"shape:\",doc_topic_dist.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 929480/929480 [1:23:08<00:00, 186.34it/s]"],"name":"stderr"},{"output_type":"stream","text":["time taken to conevrt to topics 83.15902031262716 minutes\n","shape: (929480, 750)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"D6SU93QFKS_Z","colab_type":"code","colab":{}},"source":["def jensen_shannon(query, matrix):\n","    \"\"\"\n","    This function implements a Jensen-Shannon similarity\n","    between the input query (an LDA topic distribution for a document)\n","    and the entire corpus of topic distributions.\n","    It returns an array of length M where M is the number of documents in the corpus\n","    \"\"\"\n","    # lets keep with the p,q notation above\n","    p = query[None,:].T # take transpose\n","    q = matrix[None,:].T # transpose matrix\n","    m = 0.5*(p + q)\n","    return np.sqrt(0.5*(entropy(p,m) + entropy(q,m)))[0]\n","\n","def get_most_similar_documents(query,matrix,k=5):\n","    \"\"\"\n","    This function implements the Jensen-Shannon distance above\n","    and retruns the top k indices of the smallest jensen shannon distances\n","    \"\"\"\n","    sims = np.array([jensen_shannon(query,p) for p in matrix]) # list of jensen shannon distances\n","    return sims.argsort()[:k] # the top k positional index of the smallest Jensen Shannon distances"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5bjP4ibLiDS","colab_type":"code","colab":{}},"source":["query = \"dataframe filter rows pandas\"\n","query_bow = dictionary_lda.doc2bow([w for w in nltk.word_tokenize(query) if w in model_w2v.wv.vocab])\n","\n","query_doc_distribution = np.array([tup[1] for tup in model_lda.get_document_topics(bow=query_bow)])\n","\n","query_sim_ids = get_most_similar_documents(query_doc_distribution,doc_topic_dist)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7wtGn38Lkr2","colab_type":"code","outputId":"d41cfb91-e2d5-4d83-cc73-efd7fb3ad1d1","executionInfo":{"status":"ok","timestamp":1582982825356,"user_tz":-330,"elapsed":104527,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["most_similar_df = data[data.index.isin(query_sim_ids)]\n","most_similar_df['title']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10512                 How to do a column sum in Tensorflow?\n","144695                      Join pandas series of multIndex\n","626721                      SQLAlchemy Relationship Filter?\n","636914               What is as_index in groupby in pandas?\n","716673    How to get the column name when iterating thro...\n","Name: title, dtype: object"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"J8lTnIoANzag","colab_type":"code","colab":{}},"source":["np.save(modelsDirectory+'doc_topic_dist', doc_topic_dist)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhB7tbhnEYHi","colab_type":"code","colab":{}},"source":["drive.flush_and_unmount()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jDJHFWAsWOlX","colab_type":"text"},"source":["#<h1>Search Engine</h1>"]},{"cell_type":"code","metadata":{"id":"i-hH44LpfE70","colab_type":"code","colab":{}},"source":["from PythonModules import DataPreProcess,StackOverFlowTagModel\n","\n","with open(modelsDirectory+'tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)\n","  \n","with open(modelsDirectory+'multiLabel.pickle', 'rb') as handle:\n","    encoder = pickle.load(handle)\n","\n","tagModel = StackOverFlowTagModel.buildModel()\n","tagModel.load_weights(modelsDirectory  + \"tagClassifier/best1.hdf5\")\n","\n","all_tags = sparse.csr_matrix(encoder.transform(data['tags']))\n","\n","def predict_tags(model,query,encoder,printTags=False):\n","    query_process = DataPreProcess.TextPreprocessor().transform(query)\n","    query_token = tokenizer.texts_to_sequences([query_process])\n","    query_pad = pad_sequences(query_token, maxlen=150, padding='pre')\n","\n","    prediction = model.predict(query_pad)[0]\n","    prediction = np.array(prediction >= 0.5,dtype=np.int32)\n","    \n","    tags = encoder.inverse_transform(np.array([prediction]))\n","    if(printTags):\n","        print(\"Predicted Tags: for '{0}' is {1}\".format(query,tags))\n","    return query_process,prediction,tags"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QCctQqGZlK27","colab":{}},"source":["def stackOverflow_searchEngine(query, data,tagModel, all_tags,all_sentence_emb,vectorizerFunc, model,model2=None, k = 5):\n","    start_time = time.time()\n","    query,query_tag_prediction,tags = predict_tags(tagModel,query,encoder)\n","    query_tag_prediction = query_tag_prediction.reshape(1,-1)\n","    \n","    if model2 is None:\n","        query_vect = vectorizerFunc([query], model)   # Vectorize the user query\n","    else:\n","        query_vect = vectorizerFunc([query], model,model2)   # Vectorize the user query\n","    \n","    # Calculate Cosine similarites for the query and all titles\n","    cosine_similarities = pd.Series(cosine_similarity(query_vect, all_sentence_emb)[0])\n","\n","    tagWeight = pd.Series(cosine_similarity(query_tag_prediction, all_tags)[0])\n","    \n","    # Custom Similarity Measure\n","    cosine_similarities = cosine_similarities*(1 + 0.5*tagWeight)\n","    cosine_similarities = cosine_similarities*(1 + 0.1*data.score)\n","\n","    return list(cosine_similarities.nlargest(int(k)).index),time.time() - start_time\n","\n","\n","\n","def compareResults(query,data):\n","    indexDict = {}\n","\n","    query_process,query_tag_prediction,tags = predict_tags(tagModel,query,encoder)\n","\n","    indexDict['Avg W2V'] = stackOverflow_searchEngine(query_process, data, tagModel, all_tags, avg_W2V_emb, AvgWord2VecEmbeddings, model_w2v)\n","\n","    indexDict['TF-IDF'] = stackOverflow_searchEngine(query_process, data, tagModel, all_tags, TF_IDF_W2V_emb,TF_IDF_Word2VecEmbeddings,model_w2v,model_tfidf)\n","\n","    indexDict['SIF'] = stackOverflow_searchEngine(query_process, data, tagModel, all_tags, SIF_W2V_emb, SIFWord2VecEmbeddings, model_w2v)\n","\n","    indexDict['USE'] = stackOverflow_searchEngine(query, data, tagModel, all_tags, USE_emb,USE_Embeddings,model_USE)\n","\n","    indexDict['BERT'] = stackOverflow_searchEngine(query, data, tagModel, all_tags, BERT_emb,BERT_Embeddings, model_bert)\n","\n","    output = \"\"\n","    output += \"<h1 style='text-align:center'> Top results for '\" + query + \"'</h1>\"\n","    output += \"<h2 style='text-align:center'> Tags: \" + str(tags) + \" </h2>\"\n","    output += \"</br><table> <tr>\"\n","    for i in indexDict.keys():\n","        output += \"<th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;\\\n","        font-weight:bold'><div>\" + i + \"</div></th>\"\n","    output += \"</tr>\"\n","\n","    output += \"<tr>\"\n","    for modelName in indexDict.keys():\n","        output += \"<td style='width:300px;height:400px;border:1px solid black;font-size:20px;'>\"\n","        output += \"<ol>\"\n","        for idx,index in enumerate(indexDict[modelName][0]):\n","            output += \"<li style='margin-bottom: 1em'>\" + data.title[index] + \"(\" + \\\n","                      \"<a href = 'https://stackoverflow.com/questions/\"+str(data.id[index])+\"'>link</a>\" +  \")</li>\"\n","        output += \"</ol>\"\n","        output += \"<div style='text-align:center;font-size:18px'> Time taken to retrive results: \" + \"{0:.2f}\".format(indexDict[modelName][1]) + \\\n","                  \" seconds </div></td>\"\n","    output += \"</tr>\"\n","\n","    output += \"</table>\"\n","    display(HTML(output))\n","    return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ALeAMa13tep9","colab_type":"code","outputId":"b16dc894-02e7-4960-c1e9-b94746823b12","executionInfo":{"status":"ok","timestamp":1583926480233,"user_tz":-330,"elapsed":14990,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":869}},"source":["query = \"How to Perform a groupby with sum in a dataframe?\"\n","compareResults(query,data)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<h1 style='text-align:center'> Top results for 'How to Perform a groupby with sum in a dataframe?'</h1><h2 style='text-align:center'> Tags: [('pandas', 'python')] </h2></br><table> <tr><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>Avg W2V</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>TF-IDF</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>SIF</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>USE</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>BERT</div></th></tr><tr><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Pandas - Get value as frequency in groupby(<a href = 'https://stackoverflow.com/questions/37604496'>link</a>)</li><li style='margin-bottom: 1em'>Combining groupby and apply in multiIndex DataFrames(<a href = 'https://stackoverflow.com/questions/40409724'>link</a>)</li><li style='margin-bottom: 1em'>Code Optimization for groupby(<a href = 'https://stackoverflow.com/questions/48932379'>link</a>)</li><li style='margin-bottom: 1em'>pandas groupby without turning grouped by column into index(<a href = 'https://stackoverflow.com/questions/32059397'>link</a>)</li><li style='margin-bottom: 1em'>After Grouping ..Sum of a column values based on the groups in pandas dataframe(<a href = 'https://stackoverflow.com/questions/57063253'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.03 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>groupby 1 column and sum of other columns as new dataframe pandas(<a href = 'https://stackoverflow.com/questions/45323914'>link</a>)</li><li style='margin-bottom: 1em'>Code Optimization for groupby(<a href = 'https://stackoverflow.com/questions/48932379'>link</a>)</li><li style='margin-bottom: 1em'>Combining groupby and apply in multiIndex DataFrames(<a href = 'https://stackoverflow.com/questions/40409724'>link</a>)</li><li style='margin-bottom: 1em'>Pandas - Get value as frequency in groupby(<a href = 'https://stackoverflow.com/questions/37604496'>link</a>)</li><li style='margin-bottom: 1em'>pandas dataframe sum with groupby(<a href = 'https://stackoverflow.com/questions/40826979'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.34 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>groupby 1 column and sum of other columns as new dataframe pandas(<a href = 'https://stackoverflow.com/questions/45323914'>link</a>)</li><li style='margin-bottom: 1em'>Code Optimization for groupby(<a href = 'https://stackoverflow.com/questions/48932379'>link</a>)</li><li style='margin-bottom: 1em'>How to access python groupby objects values(<a href = 'https://stackoverflow.com/questions/44815888'>link</a>)</li><li style='margin-bottom: 1em'>Pandas - Get value as frequency in groupby(<a href = 'https://stackoverflow.com/questions/37604496'>link</a>)</li><li style='margin-bottom: 1em'>Combining groupby and apply in multiIndex DataFrames(<a href = 'https://stackoverflow.com/questions/40409724'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.15 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>How to unpivot a pandas dataframe based on some grouped column?(<a href = 'https://stackoverflow.com/questions/54921609'>link</a>)</li><li style='margin-bottom: 1em'>Dask Dataframe groupby has no len()(<a href = 'https://stackoverflow.com/questions/48726649'>link</a>)</li><li style='margin-bottom: 1em'>Apply a weighted average function to a dataframe without grouping it, as if it was a single group(<a href = 'https://stackoverflow.com/questions/29969430'>link</a>)</li><li style='margin-bottom: 1em'>Filtering Pandas Dataframe Aggregate(<a href = 'https://stackoverflow.com/questions/33404492'>link</a>)</li><li style='margin-bottom: 1em'>Pandas python Initializing groupby object with empty groups(<a href = 'https://stackoverflow.com/questions/25656564'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.89 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Numpy: vectorize sum of lagged differences(<a href = 'https://stackoverflow.com/questions/29820207'>link</a>)</li><li style='margin-bottom: 1em'>How to get the aggregate result only on the first occurrence, and 0 to the other, in a computation with groupby and transform?(<a href = 'https://stackoverflow.com/questions/57408214'>link</a>)</li><li style='margin-bottom: 1em'>Calculation between groups in a Pandas multiindex dataframe(<a href = 'https://stackoverflow.com/questions/33292944'>link</a>)</li><li style='margin-bottom: 1em'>multiple row selection in multi indexed dataframe(<a href = 'https://stackoverflow.com/questions/40666466'>link</a>)</li><li style='margin-bottom: 1em'>Map two dataframes and perform sum operation using a dictionary(<a href = 'https://stackoverflow.com/questions/56878370'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 4.13 seconds </div></td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"LoGH8gcKnCYm","colab_type":"code","outputId":"2fff4e19-2ec8-4047-bff8-db9d7b5111f0","executionInfo":{"status":"ok","timestamp":1583927075642,"user_tz":-330,"elapsed":15976,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":749}},"source":["query = \"How to do web scraping?\"\n","compareResults(query,data)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<h1 style='text-align:center'> Top results for 'How to do web scraping?'</h1><h2 style='text-align:center'> Tags: [('java',)] </h2></br><table> <tr><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>Avg W2V</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>TF-IDF</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>SIF</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>USE</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>BERT</div></th></tr><tr><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Is Heritrix3.2.0 able to crawl ajax-based web sites?(<a href = 'https://stackoverflow.com/questions/29458870'>link</a>)</li><li style='margin-bottom: 1em'>Web scraping with Java(<a href = 'https://stackoverflow.com/questions/3202305'>link</a>)</li><li style='margin-bottom: 1em'>Web scraping with Python(<a href = 'https://stackoverflow.com/questions/2081586'>link</a>)</li><li style='margin-bottom: 1em'>Use Django Framework with Website and Stand-alone App(<a href = 'https://stackoverflow.com/questions/950790'>link</a>)</li><li style='margin-bottom: 1em'>Python web scraping - Where to begin(<a href = 'https://stackoverflow.com/questions/37932621'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.25 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Web scraping with Java(<a href = 'https://stackoverflow.com/questions/3202305'>link</a>)</li><li style='margin-bottom: 1em'>Web mining or scraping or crawling? What tool/library should I use?(<a href = 'https://stackoverflow.com/questions/7722876'>link</a>)</li><li style='margin-bottom: 1em'>Is Heritrix3.2.0 able to crawl ajax-based web sites?(<a href = 'https://stackoverflow.com/questions/29458870'>link</a>)</li><li style='margin-bottom: 1em'>Python web scraping - Where to begin(<a href = 'https://stackoverflow.com/questions/37932621'>link</a>)</li><li style='margin-bottom: 1em'>Scraping a website with python 3 that requires login(<a href = 'https://stackoverflow.com/questions/47438699'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.37 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Web scraping with Java(<a href = 'https://stackoverflow.com/questions/3202305'>link</a>)</li><li style='margin-bottom: 1em'>Python web scraping - Where to begin(<a href = 'https://stackoverflow.com/questions/37932621'>link</a>)</li><li style='margin-bottom: 1em'>Web mining or scraping or crawling? What tool/library should I use?(<a href = 'https://stackoverflow.com/questions/7722876'>link</a>)</li><li style='margin-bottom: 1em'>Return data from URL with Python(<a href = 'https://stackoverflow.com/questions/36776318'>link</a>)</li><li style='margin-bottom: 1em'>Screen Scraping in Python(<a href = 'https://stackoverflow.com/questions/6529633'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.25 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Web scraping with Java(<a href = 'https://stackoverflow.com/questions/3202305'>link</a>)</li><li style='margin-bottom: 1em'>Web Scrape in Python(<a href = 'https://stackoverflow.com/questions/37553882'>link</a>)</li><li style='margin-bottom: 1em'>Web Scraping specific page with Python(<a href = 'https://stackoverflow.com/questions/47475790'>link</a>)</li><li style='margin-bottom: 1em'>Python: scraping results of webpage of which results are generated server-side(<a href = 'https://stackoverflow.com/questions/34403689'>link</a>)</li><li style='margin-bottom: 1em'>web scraping java beginner(<a href = 'https://stackoverflow.com/questions/6446356'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 3.06 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Python web scraping with beautifulsoup - can't extract Principal Investigator from Clinicaltrials.gov(<a href = 'https://stackoverflow.com/questions/55421616'>link</a>)</li><li style='margin-bottom: 1em'>Web Scraping with Selenium Python [Twitter + Instagram](<a href = 'https://stackoverflow.com/questions/43033378'>link</a>)</li><li style='margin-bottom: 1em'>web scraping using beautifulsoup: separating values(<a href = 'https://stackoverflow.com/questions/32445776'>link</a>)</li><li style='margin-bottom: 1em'>Web Scraping Extract Javascript Table Selenium+Python(<a href = 'https://stackoverflow.com/questions/52010016'>link</a>)</li><li style='margin-bottom: 1em'>What Python-only HTTP/1.1 web servers are available?(<a href = 'https://stackoverflow.com/questions/1835668'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 4.54 seconds </div></td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"A-fG2gy7tWao","colab_type":"code","outputId":"8dfee6c8-cf97-4cfb-99be-13f92f56a482","executionInfo":{"status":"ok","timestamp":1583429257838,"user_tz":-330,"elapsed":16160,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":869}},"source":["query = \"How to check duplicate entries or values in a dataframe?\"\n","compareResults(query,data)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<h1 style='text-align:center'> Top results for 'How to check duplicate entries or values in a dataframe?'</h1><h2 style='text-align:center'> Tags: [('pandas', 'python')] </h2></br><table> <tr><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>Avg W2V</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>TF-IDF</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>SIF</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>USE</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>BERT</div></th></tr><tr><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Find index of all rows with null values in a particular column in pandas dataframe(<a href = 'https://stackoverflow.com/questions/44869327'>link</a>)</li><li style='margin-bottom: 1em'>Check for duplicate values in dataframe column(<a href = 'https://stackoverflow.com/questions/50242968'>link</a>)</li><li style='margin-bottom: 1em'>how to set values to rows of boolean filtered dataframe column(<a href = 'https://stackoverflow.com/questions/19497054'>link</a>)</li><li style='margin-bottom: 1em'>create Pandas Dataframe with unique index(<a href = 'https://stackoverflow.com/questions/48357853'>link</a>)</li><li style='margin-bottom: 1em'>How to replace all non-NaN entries of a dataframe with 1 and all NaN with 0(<a href = 'https://stackoverflow.com/questions/37543647'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.15 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>How to drop duplicates in Pandas DataFrame by checking for a condition?(<a href = 'https://stackoverflow.com/questions/32891325'>link</a>)</li><li style='margin-bottom: 1em'>Pandas search for duplicate rows in one column which have different values in another column(<a href = 'https://stackoverflow.com/questions/41746206'>link</a>)</li><li style='margin-bottom: 1em'>Find index of all rows with null values in a particular column in pandas dataframe(<a href = 'https://stackoverflow.com/questions/44869327'>link</a>)</li><li style='margin-bottom: 1em'>How to replace all non-NaN entries of a dataframe with 1 and all NaN with 0(<a href = 'https://stackoverflow.com/questions/37543647'>link</a>)</li><li style='margin-bottom: 1em'>Remove non-duplicated entries(<a href = 'https://stackoverflow.com/questions/33182945'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.49 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>How to drop duplicates in Pandas DataFrame by checking for a condition?(<a href = 'https://stackoverflow.com/questions/32891325'>link</a>)</li><li style='margin-bottom: 1em'>Pandas search for duplicate rows in one column which have different values in another column(<a href = 'https://stackoverflow.com/questions/41746206'>link</a>)</li><li style='margin-bottom: 1em'>Python Pandas find all rows where all values are NaN(<a href = 'https://stackoverflow.com/questions/38884538'>link</a>)</li><li style='margin-bottom: 1em'>Pandas: unique dataframe(<a href = 'https://stackoverflow.com/questions/12322779'>link</a>)</li><li style='margin-bottom: 1em'>Find duplicated rows, multiply a certain column by number of duplicates, drop duplicated rows(<a href = 'https://stackoverflow.com/questions/53943248'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.28 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Pandas: unique dataframe(<a href = 'https://stackoverflow.com/questions/12322779'>link</a>)</li><li style='margin-bottom: 1em'>Checking the duplicate values of multiple columns in a row in a dataframe.(<a href = 'https://stackoverflow.com/questions/48787485'>link</a>)</li><li style='margin-bottom: 1em'>check for duplicates in Pyspark Dataframe(<a href = 'https://stackoverflow.com/questions/50122955'>link</a>)</li><li style='margin-bottom: 1em'>Fill empty values in a dataframe based on columns in another dataframe(<a href = 'https://stackoverflow.com/questions/45883731'>link</a>)</li><li style='margin-bottom: 1em'>Find extra values after comparing two columns of dataframe python(<a href = 'https://stackoverflow.com/questions/41689746'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 3.11 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Checking the duplicate values of multiple columns in a row in a dataframe.(<a href = 'https://stackoverflow.com/questions/48787485'>link</a>)</li><li style='margin-bottom: 1em'>checking range of number and writing a value in a new column in pandas dataframe(<a href = 'https://stackoverflow.com/questions/51349581'>link</a>)</li><li style='margin-bottom: 1em'>Python pandas replace value in column(<a href = 'https://stackoverflow.com/questions/42121598'>link</a>)</li><li style='margin-bottom: 1em'>Storing dictionaries inside a dataframe that have duplicate entries in a unique value column(<a href = 'https://stackoverflow.com/questions/56950506'>link</a>)</li><li style='margin-bottom: 1em'>Replace other columns of duplicate rows with first unique value and create lookup(<a href = 'https://stackoverflow.com/questions/48781372'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 4.34 seconds </div></td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"XbtLJJmtuQhC","colab_type":"code","outputId":"f45f4907-832f-4863-8f49-8402079d80c3","executionInfo":{"status":"ok","timestamp":1583932358782,"user_tz":-330,"elapsed":16247,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":749}},"source":["query = \"How to fill missing values?\"\n","compareResults(query,data)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<h1 style='text-align:center'> Top results for 'How to fill missing values?'</h1><h2 style='text-align:center'> Tags: [('java', 'python')] </h2></br><table> <tr><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>Avg W2V</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>TF-IDF</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>SIF</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>USE</div></th><th style='padding:0px;margin:0px;border:1px solid black;width:300px;text-align:center;font-size:25px;        font-weight:bold'><div>BERT</div></th></tr><tr><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Filling the missing index and filling its value with 0(<a href = 'https://stackoverflow.com/questions/50690963'>link</a>)</li><li style='margin-bottom: 1em'>Fill in missing row values in pandas dataframe(<a href = 'https://stackoverflow.com/questions/29357785'>link</a>)</li><li style='margin-bottom: 1em'>Pandas fillna: Output still has NaN values(<a href = 'https://stackoverflow.com/questions/18127160'>link</a>)</li><li style='margin-bottom: 1em'>Opposite of dropna() in pandas(<a href = 'https://stackoverflow.com/questions/46626639'>link</a>)</li><li style='margin-bottom: 1em'>Dealing with missing value in a column using pandas(<a href = 'https://stackoverflow.com/questions/54005192'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.16 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Filling the missing index and filling its value with 0(<a href = 'https://stackoverflow.com/questions/50690963'>link</a>)</li><li style='margin-bottom: 1em'>Pandas - filling NaNs in Categorical data(<a href = 'https://stackoverflow.com/questions/32718639'>link</a>)</li><li style='margin-bottom: 1em'>Pandas fillna: Output still has NaN values(<a href = 'https://stackoverflow.com/questions/18127160'>link</a>)</li><li style='margin-bottom: 1em'>Filling missing values with mode of column relative to another column in Python(<a href = 'https://stackoverflow.com/questions/46941874'>link</a>)</li><li style='margin-bottom: 1em'>loop drop columns over number of missing values(<a href = 'https://stackoverflow.com/questions/53331157'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.45 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Filling the missing index and filling its value with 0(<a href = 'https://stackoverflow.com/questions/50690963'>link</a>)</li><li style='margin-bottom: 1em'>Filling missing lines with \"nan\" with pandas reindex(<a href = 'https://stackoverflow.com/questions/24444328'>link</a>)</li><li style='margin-bottom: 1em'>Pandas - filling NaNs in Categorical data(<a href = 'https://stackoverflow.com/questions/32718639'>link</a>)</li><li style='margin-bottom: 1em'>How to fill up this python list?(<a href = 'https://stackoverflow.com/questions/46648812'>link</a>)</li><li style='margin-bottom: 1em'>Fill with Nan when Length of values does not match length of index(<a href = 'https://stackoverflow.com/questions/57383961'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 2.18 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>Opposite of dropna() in pandas(<a href = 'https://stackoverflow.com/questions/46626639'>link</a>)</li><li style='margin-bottom: 1em'>fill multiple missing values with series based on index values(<a href = 'https://stackoverflow.com/questions/40470620'>link</a>)</li><li style='margin-bottom: 1em'>Binning with zero values in pandas(<a href = 'https://stackoverflow.com/questions/18921570'>link</a>)</li><li style='margin-bottom: 1em'>conditionally filling the missing values based on the other variables available(<a href = 'https://stackoverflow.com/questions/51001979'>link</a>)</li><li style='margin-bottom: 1em'>Adding missing time in pandas dataframe(<a href = 'https://stackoverflow.com/questions/42673064'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 3.11 seconds </div></td><td style='width:300px;height:400px;border:1px solid black;font-size:20px;'><ol><li style='margin-bottom: 1em'>How to fill missing values with similar rows median(<a href = 'https://stackoverflow.com/questions/53058069'>link</a>)</li><li style='margin-bottom: 1em'>How to fill nan values with rolling mean in pandas(<a href = 'https://stackoverflow.com/questions/49172914'>link</a>)</li><li style='margin-bottom: 1em'>Fill in missing row values in pandas dataframe(<a href = 'https://stackoverflow.com/questions/29357785'>link</a>)</li><li style='margin-bottom: 1em'>Using xlrd, how to replace missing/NaN cells(<a href = 'https://stackoverflow.com/questions/32142293'>link</a>)</li><li style='margin-bottom: 1em'>transform on multiple columns to interpolate/copy missing values(<a href = 'https://stackoverflow.com/questions/50320776'>link</a>)</li></ol><div style='text-align:center;font-size:18px'> Time taken to retrive results: 4.81 seconds </div></td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"5WiO9PssuYCL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}